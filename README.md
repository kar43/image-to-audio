# Image-to-Sound Synthesis using Generative Adversarial Network

Master's project on audio generation from images using Conditional GAN (University of York).

<img src='https://github.com/user-attachments/assets/6f115df0-7429-47ef-9402-45ae899d2939' width=990>

## Examples of generated audio spectrograms


#### Using training data:

<img src='https://github.com/user-attachments/assets/65c90140-f9da-4774-99fd-d9ab76f88cd2) ![image](https://github.com/user-attachments/assets/b58e73c5-5756-4d3a-9a45-14e0f457ee25' width=410>
<img src='https://github.com/user-attachments/assets/fa5e9f11-164d-4fd1-aa5b-93d5feb28b61' width=395>



#### Using test data:

<img src='https://github.com/user-attachments/assets/5bee20cd-e71d-44f6-b302-9a8797f0f2a0) ![image](https://github.com/user-attachments/assets/aa5becb5-4f70-4d4c-b44c-bb131138e12e' width=310>
<img src='https://github.com/user-attachments/assets/5802a8a1-0769-436b-a4d0-5117919b845a' width=395>

## Running the model

#### Training
To train the model, execute train.py

#### Testing
To test the model, execute test.py

#### Options
A number of options can be specified to customise the configuration of the model, its training and testing.
Options are specified in the files under options directory

#### Command line
Examples of commands are provided in Commands.txt

## Acknowledgments

The implementation is based on the code provided in [this public repository](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix?tab=readme-ov-file).
